{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%shell\r\n",
    "pip install pymanopt\r\n",
    "pip install git+https://github.com/geoopt/geoopt.git\r\n",
    "if [ -d NeuralCollapse ]\r\n",
    "then\r\n",
    "    rm -rf NeuralCollapse\r\n",
    "fi\r\n",
    "git clone https://github.com/10258392511/NeuralCollapse.git\r\n",
    "cp NeuralCollapse/problem.py /usr/local/lib/python3.7/dist-packages/pymanopt/core/problem.py\r\n",
    "cp -r NeuralCollapse/* .\r\n",
    "\r\n",
    "%load_ext autoreload \r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "import geoopt\r\n",
    "import pickle\r\n",
    "\r\n",
    "from run_cifar100.demos import demo_manifold_tensor, demo_manifold_param\r\n",
    "demo_manifold_tensor()\r\n",
    "# demo_manifold_param()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W: Tensor on Sphere manifold containing:\n",
      "tensor([[-0.9497,  0.3132],\n",
      "        [ 0.3278, -0.9448],\n",
      "        [ 0.8772,  0.4801]], requires_grad=True)\n",
      "norm: tensor([1., 1., 1.], grad_fn=<CopyBackwards>)\n",
      "W_next: tensor([[-0.9739,  0.2268],\n",
      "        [ 0.2893, -0.9572],\n",
      "        [ 0.9104,  0.4137]])\n",
      "norm: tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "## get datasets\r\n",
    "from run_cifar100.datasets import select_k_cls\r\n",
    "# slecet k class,dim is not fixed in this sample \r\n",
    "BATCH_SIZE = 128\r\n",
    "train_loader, test_loader = select_k_cls(num_cls=5, batch_size=BATCH_SIZE, if_plot_batch=False)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# test of dataset \r\n",
    "from torchvision.datasets import CIFAR100\r\n",
    "num_cls = 10\r\n",
    "tmp_train_dataset = CIFAR100(\"./data\", transform=None, download=True)\r\n",
    "classes = np.random.choice(len(tmp_train_dataset.classes), num_cls, replace=False)\r\n",
    "print(\"classes: {}\".format(classes))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "classes: [59 36 48 23  8 29  6 42 14 61]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n",
    "print(\"device: {}\".format(DEVICE))\r\n",
    "\r\n",
    "from run_cifar100.models import ResNetAdapt # use resnets for function\r\n",
    "M, K = 2, 5 # M means manifold, K means class_numbers\r\n",
    "model = ResNetAdapt(M, K, True, True)\r\n",
    "\r\n",
    "opt = geoopt.optim.RiemannianAdam([param for param in model.parameters() if param.requires_grad])\r\n",
    "step_size = 10\r\n",
    "gamma = 0.8\r\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=step_size, gamma=gamma)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from train_K_gt_d import train_cli"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "K = 4\r\n",
    "feature_man = True\r\n",
    "weight_man = True\r\n",
    "weight_alpha = 0.1\r\n",
    "\r\n",
    "args = {\"M\": 2, \r\n",
    "    \"K\": K, \r\n",
    "    \"epoch\": 10, \r\n",
    "    \"batch_size\": 128, \r\n",
    "    \"lr\": 2e-2,\r\n",
    "    \"scheduler\": False,\r\n",
    "    \"feature_man\": feature_man,\r\n",
    "    \"W_man\": weight_man,\r\n",
    "    'weight_alpha': weight_alpha}\r\n",
    "        \r\n",
    "train_cli(**args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6c665345045d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     'weight_alpha': weight_alpha}\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\program_training\\Umich_Intern\\Neural Collapse with Oblique Constrained Features\\train_K_gt_d.py\u001b[0m in \u001b[0;36mtrain_cli\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mout_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tr_loss, tr_acc, val_loss, val_acc = train_epoch(model, train_loader, test_loader, opt, device,\n\u001b[1;32m---> 53\u001b[1;33m                                  train_args, scheduler=scheduler, out_dict=out_dict)\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program_training\\Umich_Intern\\Neural Collapse with Oblique Constrained Features\\run_cifar100\\utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, test_loader, optimizer, device, train_args, scheduler, out_dict)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mvalidate_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validate_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"epoch {epoch + 1}/{epochs}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         local_tr_loss, local_tr_acc, local_val_loss, local_val_acc = train(model, train_loader, test_loader,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pyman\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pyman\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             raise ImportError(\n\u001b[1;32m--> 113\u001b[1;33m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pyman': conda)"
  },
  "interpreter": {
   "hash": "d66156afb01098d949d7a0a5034aa0e76b793b41e6c2e72613ea930e41d6bd62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}